{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data\n",
    "1. Generate the Heterogeneous graph\n",
    "2. Generate the feature set from the clinical notes.\n",
    "3. Generate the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Diseases: 203\n"
     ]
    }
   ],
   "source": [
    "import sys, os, copy\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# OAK\n",
    "sys.path.append('../data_generation')\n",
    "\n",
    "from  ModelFunctions import *\n",
    "# ============================================================================\n",
    "num_Diseases = 203\n",
    "# ============================================================================\n",
    "print(f\"Number of Diseases: {num_Diseases}\")\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_statistics(G):\n",
    "    Nodes = list(G.nodes())\n",
    "\n",
    "    Patients =    [v for v in Nodes if v[0]=='C']\n",
    "    Visits =      [v for v in Nodes if v[0]=='V']\n",
    "    Medications = [v for v in Nodes if v[0]=='M']\n",
    "    Diagnosis =   [v for v in Nodes if v[0]=='D']\n",
    "    Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "\n",
    "    print(f'number of patients = {len(Patients)}')\n",
    "    print(f'number of visits = {len(Visits)}')\n",
    "    print(f'number of Medication = {len(Medications)}')\n",
    "    print(f'number of Diagnoses = {len(Diagnosis)}')\n",
    "    print(f'number of Procedures = {len(Procedures)}')\n",
    "    print(f'number of Edges = {G.number_of_edges()}')\n",
    "    \n",
    "    print('------------------------------------------\\n')\n",
    "\n",
    "def calculate_percentage_of_zeros(A):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of zero values in a 2D numpy array.\n",
    "\n",
    "    Parameters:\n",
    "    A (numpy.ndarray): 2D numpy array\n",
    "\n",
    "    Returns:\n",
    "    float: Percentage of zero values\n",
    "    \"\"\"\n",
    "    # Count the number of zero values\n",
    "    num_zeros = np.count_nonzero(A == 0)\n",
    "\n",
    "    # Count the total number of values\n",
    "    total_values = A.size\n",
    "\n",
    "    # Calculate the percentage of zero values\n",
    "    percentage_zeros = (num_zeros / total_values) * 100\n",
    "\n",
    "    return percentage_zeros\n",
    "\n",
    "# Removing <patients to delete> from HG\n",
    "def remove_patients_and_linked_visits(nodes, HG):\n",
    "    '''remove patients and their visits from HG'''\n",
    "    print('Number of PATIENTS to remove: ', len(nodes))\n",
    "    \n",
    "    new_HG = deepcopy(HG)\n",
    "    nodes_to_remove = []\n",
    "    for node in nodes:\n",
    "        for v in HG.neighbors(node):\n",
    "            if v[0]=='V':\n",
    "                nodes_to_remove.append(v)\n",
    "        nodes_to_remove.append(node)\n",
    "    print('Number of nodes to remove: ', len(nodes_to_remove))\n",
    "    new_HG.remove_nodes_from(nodes_to_remove)\n",
    "    return new_HG                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate the Heterogeneous graph\n",
    "### The entire graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the graph...\n",
      "Use the patients inside the new DF....\n",
      "For the given diagnosis, extract the sub dataframe....\n",
      "Diagnoses frequency =  ['401', '427', '428', '276', '250', '414', '272', '518', '285', '584', 'V45', '530', 'V58', '599', 'E87', 'V10', '585', '403', '038', 'V30', '765', '998', '305', 'V29', '780', '997', 'V05', '424', '995', '785', '410', '244', '041', '458', '707', 'V15', '486', '996', '496', 'V12', '790', '287', 'E93', '348', '507', '493', '311', '511', '571', '412', '770', 'E88', '300', '733', '774', '278', '070', '416', '787', '578', '197', '198', '482', '327', 'V49', '274', 'V43', '572', '779', '280', 'E84', '440', '303', '425', '789', '286', '788', 'V50', '294', '600', '411', '560', '443', '288', '357', '577', '441', '682', '453', 'V44', '112', '799', '438', '345', '008', '293', '275', '426', '786', '562', '434', '715', 'E81', '784', '564', '263', '362', '433', '331', '852', '724', '296', '431', '491', '805', '576', '769', '569', '519', 'V42', '338', '807', '162', 'V31', '291', '535', '574', '553', 'E94', '873', '415', '413', '456', '567', '570', '729', '802', '284', '593', 'V66', '512', '423', '745', '396', 'V09', '999', 'V17', '459', '728', '782', '775', '437', '342', '397', 'V46', '304', '365', '557', '537', '196', '349', 'E95', '253', '747', 'V85', '238', '583', '536', '295', '714', '568', '801', '492', '860', 'E92', '730', '430', '255', '781', 'E91', '808', '289', '746', '292', '478', '346', '333', '776', '455', '429', '531', '693', '515', '042', '344', '721', '710', 'V70', 'V64', '444', '532', '211', '719']\n",
      "General Information:\n",
      "---------------------------\n",
      "Number of Patients = 46520\n",
      "Number of Diagnosis = 203\n",
      "Number of procedures = 89\n",
      "Number of Medication = 592\n",
      "---------------------------------\n",
      "Getting the Homogeneous graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/almusawiaf/MyDocuments/PhD_Projects/PSG_LOS/Data_Generation/ModelFunctions.py:170: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['C_109' 'C_109' 'C_109' ... 'C_97503' 'C_97503' 'C_97503']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  new_df.loc[:, id1] = c1 + '_' + new_df[id1].astype(str)\n",
      "/home/almusawiaf/MyDocuments/PhD_Projects/PSG_LOS/Data_Generation/ModelFunctions.py:171: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['V_172335' 'V_172335' 'V_172335' ... 'V_188195' 'V_188195' 'V_188195']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  new_df.loc[:, id2] = c2 + '_' + new_df[id2].astype(str)\n",
      "/home/almusawiaf/MyDocuments/PhD_Projects/PSG_LOS/Data_Generation/ModelFunctions.py:170: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['V_172335' 'V_172335' 'V_172335' ... 'V_188195' 'V_188195' 'V_188195']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  new_df.loc[:, id1] = c1 + '_' + new_df[id1].astype(str)\n",
      "/home/almusawiaf/MyDocuments/PhD_Projects/PSG_LOS/Data_Generation/ModelFunctions.py:170: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['V_154460' 'V_130856' 'V_130856' ... 'V_150871' 'V_150871' 'V_150871']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  new_df.loc[:, id1] = c1 + '_' + new_df[id1].astype(str)\n",
      "/home/almusawiaf/MyDocuments/PhD_Projects/PSG_LOS/Data_Generation/ModelFunctions.py:170: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['V_159647' 'V_159647' 'V_159647' ... 'V_100969' 'V_100969' 'V_100969']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  new_df.loc[:, id1] = c1 + '_' + new_df[id1].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done --> Getting the Homogeneous graphs...\n",
      "Creating the Heterogeneous graph...\n",
      "number of patients = 46437\n",
      "number of visits = 58897\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "Done --> Creating the Heterogeneous graph...\n",
      "number of patients = 46437\n",
      "number of visits = 58897\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "print('Creating the graph...')\n",
    "\n",
    "new_Diagnosis, new_Prescriptions, new_Procedures = load_patients_data(num_Diseases)\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "CV_edges , VD_edges , VP_edges , VM_edges = get_homogeneous_graphs(new_Diagnosis, new_Prescriptions, new_Procedures)\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "HG = get_Heterogeneous_graph(CV_edges , VD_edges , VP_edges , VM_edges)\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "Patients, Visits, Medications, Diagnosis, Procedures, _ = get_Nodes(HG)\n",
    "Nodes = Patients + Visits + Medications + Diagnosis  + Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HADM_ID       LOS\n",
      "0   165315  1.144444\n",
      "1   152223  5.496528\n",
      "2   124321  6.768056\n",
      "3   161859  2.856944\n",
      "4   129635  3.534028\n"
     ]
    }
   ],
   "source": [
    "def get_LOS(Nodes, G):\n",
    "    def get_HADM_ID_LOS():\n",
    "        df_admissions = pd.read_csv(f'{folder_path}/ADMISSIONS.csv')\n",
    "\n",
    "        # Ensure ADMITTIME and DISCHTIME are in datetime format\n",
    "        df_admissions['ADMITTIME'] = pd.to_datetime(df_admissions['ADMITTIME'])\n",
    "        df_admissions['DISCHTIME'] = pd.to_datetime(df_admissions['DISCHTIME'])\n",
    "        \n",
    "        # Calculate the Length of Stay (LOS) in days\n",
    "        df_admissions['LOS'] = (df_admissions['DISCHTIME'] - df_admissions['ADMITTIME']).dt.total_seconds() / (24 * 60 * 60)\n",
    "        \n",
    "        return df_admissions[['HADM_ID', 'LOS']]\n",
    "\n",
    "    LOS_DF = get_HADM_ID_LOS()\n",
    "    print(LOS_DF.head(5))\n",
    "    \n",
    "    LOS = []\n",
    "    for node in Nodes:\n",
    "        if node[0] == 'V':\n",
    "            # Extract the LOS value for the corresponding HADM_ID\n",
    "            los_value = LOS_DF[LOS_DF['HADM_ID'] == int(node[2:])]['LOS']\n",
    "            \n",
    "            if not los_value.empty:\n",
    "                # If a value is found, append the first value of the Series\n",
    "                LOS.append(los_value.iloc[0])\n",
    "            else:\n",
    "                # Append 0 if no value is found for that HADM_ID\n",
    "                LOS.append(0)\n",
    "        else:\n",
    "            LOS.append(0)\n",
    "    \n",
    "    return LOS\n",
    "\n",
    "# Example usage:\n",
    "LOS = np.array(get_LOS(Nodes, HG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.20763889,  4.08055556, 12.06180556, ..., 16.78819444,\n",
       "        5.91597222,  5.52291667])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_indeces = {k: i for i, k in enumerate(Nodes)}\n",
    "\n",
    "LOS[[nodes_indeces[p] for p in Nodes if p[0]=='V']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Isolated nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients = 46437\n",
      "number of visits = 58897\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Edges = 769929\n",
      "------------------------------------------\n",
      "\n",
      "Number of PATIENTS to remove:  0\n",
      "Number of nodes to remove:  0\n",
      "number of patients = 46437\n",
      "number of visits = 58897\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Edges = 769929\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = [v for v in HG.nodes() if HG.degree(v)==0]\n",
    "G_statistics(HG)    \n",
    "new_HG = remove_patients_and_linked_visits(isolated_nodes, HG)\n",
    "G_statistics(new_HG)    \n",
    "del HG\n",
    "HG = deepcopy(new_HG)\n",
    "del new_HG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients = 46437\n",
      "number of visits = 58897\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n"
     ]
    }
   ],
   "source": [
    "Patients, Visits, Medications, Diagnosis, Procedures, _ = get_Nodes(HG)\n",
    "Nodes2 = Patients + Visits + Medications + Diagnosis  + Procedures\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create lists of node sets\n",
    "patients    = [p for p in HG.nodes() if p[0] == 'C']  # Patient nodes\n",
    "visits      = [v for v in HG.nodes() if v[0] == 'V']    # Visit nodes\n",
    "medications = [m for m in HG.nodes() if m[0] == 'M']  # Medication nodes\n",
    "diagnoses   = [d for d in HG.nodes() if d[0] == 'D']    # Diagnosis nodes\n",
    "procedures  = [p for p in HG.nodes() if p[0] == 'P']   # Procedure nodes\n",
    "\n",
    "# Combine all relevant rows and columns\n",
    "row_nodes = patients + visits + medications + diagnoses + procedures\n",
    "col_nodes = medications + diagnoses + procedures\n",
    "\n",
    "# Step 2: Create index mappings for rows and columns\n",
    "node_idx = {node: idx for idx, node in enumerate(Nodes)}  # Full graph node index\n",
    "row_indices = [node_idx[node] for node in row_nodes]  # Indices for rows\n",
    "col_indices = [node_idx[node] for node in col_nodes]  # Indices for columns\n",
    "\n",
    "# Step 3: Extract the full adjacency matrix for the graph (this is often stored or built beforehand)\n",
    "# Assuming you have the full adjacency matrix `adj_matrix` (NxN for the full graph):\n",
    "adj_matrix = nx.adjacency_matrix(HG)\n",
    "\n",
    "# Step 4: Extract the submatrix of interest (rows for Patients, Visits, Medications, Diagnoses, Procedures)\n",
    "# and columns for Medications, Diagnoses, Procedures\n",
    "X = adj_matrix[row_indices, :][:, col_indices]\n",
    "\n",
    "# Now submatrix contains the rows for Patients, Visits, Medications, Diagnoses, Procedures \n",
    "# and columns for Medications, Diagnoses, Procedures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106218, 884) (106218,)\n",
      "../Data/HG\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, LOS.shape)\n",
    "saving_path = f'../Data/HG'\n",
    "print(saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to ../Data/HG/Nodes.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_list_as_pickle(L, given_path):\n",
    "    print(f'saving to {given_path}')\n",
    "    with open(given_path, 'wb') as file:\n",
    "        pickle.dump(L, file)\n",
    "\n",
    "torch.save(X, f'{saving_path}/X.pt')\n",
    "torch.save(LOS, f'{saving_path}/Y.pt')\n",
    "nx.write_gml(HG, f'{saving_path}/HG.gml')\n",
    "save_list_as_pickle(Nodes2, f'{saving_path}/Nodes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<106218x884 sparse array of type '<class 'numpy.int64'>'\n",
       "\twith 711125 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
