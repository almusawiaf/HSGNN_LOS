{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "generate_HG is class used to generate the 203 heterogeneous graph only.\n",
    "We only included patients with diagnoses.\n",
    "'''\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "\n",
    "'''NO DEMOGRAPHICS INFORMATION ADDED'''\n",
    "\n",
    "class Generate_HG:\n",
    "    \n",
    "    def __init__(self, sampling = False, num_Patients = 500):\n",
    "\n",
    "        self.sampling = sampling\n",
    "        self.num_Patients = num_Patients\n",
    "        self.folder_path = '/lustre/home/almusawiaf/PhD_Projects/MIMIC_resources'\n",
    "        # self.folder_path = '/home/almusawiaf/MyDocuments/PhD_Projects/Data/MIMIC_resources'        \n",
    "        \n",
    "        print('Loading the dataframes...')\n",
    "        \n",
    "        new_Diagnosis, new_Prescriptions, new_Procedures, new_LabTest, new_MicroBio = self.load_patients_data()\n",
    "        \n",
    "        print('Extracting bipartite networks...')\n",
    "\n",
    "\n",
    "        CV = self.get_Bipartite(new_Diagnosis,    'SUBJECT_ID', 'HADM_ID',  'C', 'V', 'Visits')\n",
    "        VD = self.get_Bipartite(new_Diagnosis,    'HADM_ID', 'ICD9_CODE',   'V', 'D', 'Diagnosis')\n",
    "        VP = self.get_Bipartite(new_Procedures,   'HADM_ID', 'ICD9_CODE',   'V', 'P', 'Procedures')\n",
    "        VM = self.get_Bipartite(new_Prescriptions,'hadm_id', 'drug',        'V', 'M', 'Medications')\n",
    "        VL = self.get_Bipartite(new_LabTest,      'HADM_ID', 'ITEMID_FLAG', 'V', 'L', 'Lab tests')\n",
    "        VB = self.get_Bipartite(new_MicroBio,     'HADM_ID', 'SPEC_ITEMID', 'V', 'B', 'MicroBiology tests')\n",
    "        \n",
    "        self.HG = nx.Graph()\n",
    "        edges_list = CV + VD + VP + VM + VB # + VL      \n",
    "                \n",
    "        self.HG.add_edges_from(edges_list)\n",
    "        G_statistics(self.HG)\n",
    "        \n",
    "        self.selecting_top_labs()       \n",
    "        self.remove_isolated_nodes()        \n",
    "        self.update_statistics()\n",
    "\n",
    "        G_statistics(self.HG)\n",
    "\n",
    "        print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    \n",
    "    def update_statistics(self):\n",
    "        Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in Nodes if v[0]=='C']\n",
    "        self.Visits =      [v for v in Nodes if v[0]=='V']\n",
    "        self.Medications = [v for v in Nodes if v[0]=='M']\n",
    "        self.Diagnosis  =  [v for v in Nodes if v[0]=='D']\n",
    "        self.Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "        self.Labs       =  [v for v in Nodes if v[0]=='L']\n",
    "        self.MicroBio   =  [v for v in Nodes if v[0]=='B']\n",
    "        self.Nodes = Nodes\n",
    "        \n",
    "\n",
    "    def get_Bipartite(self, DF, id1, id2, c1, c2, msg):\n",
    "        '''DF: dataframe, id1: row1, id2: row2, c1, c2: node code'''  \n",
    "        print(f'\\nExtracting and adding data of {msg}')\n",
    "\n",
    "        DF2    = self.getDict2(DF,  id1, id2, c1, c2)\n",
    "        return self.getEdges(DF2, id1, id2)\n",
    "    \n",
    "    def split_lab_test(self, lab_df):\n",
    "        print('Splitting lab tests')\n",
    "        # Step 1: Fill NaN values in the 'FLAG' column with 'normal'\n",
    "        lab_df['FLAG'] = lab_df['FLAG'].fillna('normal')\n",
    "        \n",
    "        # Step 2: Remove rows where 'FLAG' equals 'delta'\n",
    "        lab_df = lab_df[lab_df['FLAG'] != 'delta']\n",
    "        \n",
    "        # Step 3: Create a new DataFrame with HADM_ID and a concatenated column 'itemid_flag'\n",
    "        # Concatenate 'ITEMID' and 'FLAG' as strings\n",
    "        lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n",
    "\n",
    "        \n",
    "        # Create the new DataFrame with 'HADM_ID' and the concatenated 'itemid_flag' column\n",
    "        new_df = lab_df[['HADM_ID', 'ITEMID_FLAG']].copy()\n",
    "        print(f'Number of visits here is {len(new_df[\"HADM_ID\"].unique())}')\n",
    "\n",
    "        return new_df\n",
    "\n",
    "    def remove_isolated_nodes(self):\n",
    "        print('Removing isolated nodes')\n",
    "        self.update_statistics()\n",
    "        isolated_nodes = [v for v in self.Nodes if self.HG.degree(v)==0]\n",
    "        self.HG = remove_patients_and_linked_visits(isolated_nodes, self.HG)\n",
    "\n",
    "\n",
    "    def extract3(self, code):\n",
    "        return str(code)[:3]\n",
    "    \n",
    "    def extract2(self, code):\n",
    "        return str(code)[:2]\n",
    "    \n",
    "    def load_patients_data(self):\n",
    "        import random\n",
    "        # 1. read the prescreption file...\n",
    "        \n",
    "        # Loading the data\n",
    "        df_Medications   = pd.read_csv(f'{self.folder_path}/PRESCRIPTIONS.csv')\n",
    "        df_DiagnosisICD  = pd.read_csv(f'{self.folder_path}/DIAGNOSES_ICD.csv')    # Diagnosis!\n",
    "        df_ProceduresICD = pd.read_csv(f'{self.folder_path}/PROCEDURES_ICD.csv')    # Procedures!\n",
    "        df_labs          = pd.read_csv(f'{self.folder_path}/LABEVENTS.csv')    # Lab test!\n",
    "        df_microbio      = pd.read_csv(f'{self.folder_path}/MICROBIOLOGYEVENTS.csv')    # Microbiology!\n",
    "        \n",
    "        \n",
    "        # Handling missing values upfront (dropping rows with missing important columns)\n",
    "        df_DiagnosisICD.dropna(subset=['HADM_ID', 'ICD9_CODE'], inplace=True)\n",
    "        df_ProceduresICD.dropna(subset=['ICD9_CODE'], inplace=True)\n",
    "        df_Medications.dropna(subset=['drug'], inplace=True)\n",
    "        df_labs.dropna(subset=['HADM_ID'], inplace=True)\n",
    "        df_labs.dropna(subset=['ITEMID'], inplace=True)\n",
    "        df_microbio.dropna(subset=['SPEC_ITEMID'], inplace=True)\n",
    "        \n",
    "        # Extract unique visits and patients from the diagnosis DataFrame\n",
    "        visits = df_DiagnosisICD['HADM_ID'].unique()\n",
    "        patients = df_DiagnosisICD['SUBJECT_ID'].unique()\n",
    "\n",
    "        if self.sampling:\n",
    "            print('\\nWe are SAMPLING\\n')\n",
    "            patients = random.sample(list(patients), self.num_Patients)\n",
    "\n",
    "        df_labs = self.split_lab_test(df_labs)\n",
    "        \n",
    "        df_labs['HADM_ID'] = df_labs['HADM_ID'].astype(int)\n",
    "\n",
    "        # Filtering the data for selected patients and visits\n",
    "        print('Use the patients inside the new DataFrame....')\n",
    "        new_Diagnosis = df_DiagnosisICD[df_DiagnosisICD['HADM_ID'].isin(visits)].copy()\n",
    "        new_Procedures = df_ProceduresICD[df_ProceduresICD['HADM_ID'].isin(visits)].copy()\n",
    "        new_Medication = df_Medications[df_Medications['hadm_id'].isin(visits)].copy()\n",
    "        new_LabTest = df_labs[df_labs['HADM_ID'].isin(visits)].copy()\n",
    "        new_MicroBio = df_microbio[df_microbio['HADM_ID'].isin(visits)].copy()\n",
    "        \n",
    "        print('Dropping NaN visits')\n",
    "        new_Diagnosis.dropna(subset=['HADM_ID'], inplace=True)\n",
    "        new_Procedures.dropna(subset=['HADM_ID'], inplace=True)\n",
    "        new_Medication.dropna(subset=['hadm_id'], inplace=True)\n",
    "        new_LabTest.dropna(subset=['HADM_ID'], inplace=True)\n",
    "        new_MicroBio.dropna(subset=['HADM_ID'], inplace=True)\n",
    "    \n",
    "        new_Diagnosis['ICD9_CODE']  = new_Diagnosis['ICD9_CODE'].apply(self.extract3)\n",
    "        new_Procedures['ICD9_CODE'] = new_Procedures['ICD9_CODE'].apply(self.extract2)\n",
    "        # ----------------------------------------------------------------------------\n",
    "        \n",
    "        diag_frequency = new_Diagnosis['ICD9_CODE'].value_counts().head(203).index.tolist()        \n",
    "        new_Diagnosis  = new_Diagnosis[new_Diagnosis['ICD9_CODE'].isin(diag_frequency)]        \n",
    "        \n",
    "        # ----------------------------------------------------------------------------\n",
    "        # extracting the unique sets of nodes of diff category.\n",
    "        Procedures = sorted(new_Procedures['ICD9_CODE'].unique())\n",
    "        Medication = sorted(new_Medication['drug'].unique())\n",
    "        Diagnosis  = new_Diagnosis['ICD9_CODE'].unique()\n",
    "        LabTests   = new_LabTest['ITEMID_FLAG'].unique()\n",
    "        MicroBio   = new_MicroBio['SPEC_ITEMID'].unique()\n",
    "    \n",
    "        print('General Information:\\n---------------------------')\n",
    "        print(f'Number of Patients = {len(patients)}')\n",
    "        print(f'Number of Visits = {len(visits)}')\n",
    "        print(f'Number of Diagnosis = {len(Diagnosis)}')\n",
    "        print(f'Number of procedures = {len(Procedures)}')\n",
    "        print(f'Number of Medication = {len(Medication)}')\n",
    "        print(f'Number of Lab tests  = {len(LabTests)}')\n",
    "        print(f'Number of MicroBio   = {len(MicroBio)}')\n",
    "        print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        return new_Diagnosis, new_Medication, new_Procedures, new_LabTest, new_MicroBio\n",
    "\n",
    "\n",
    "\n",
    "    def selecting_top_labs(self):\n",
    "        self.update_statistics()\n",
    "        node_degrees = {n: self.HG.degree(n) for n in self.Nodes if n[0] == 'L'}\n",
    "        top_nodes = dict(sorted(node_degrees.items(), key=lambda item: item[1], reverse=True)[:480])\n",
    "        labs_to_delete = [n for n in node_degrees if n not in top_nodes]\n",
    "        self.HG.remove_nodes_from(labs_to_delete)\n",
    "            \n",
    "\n",
    "    def getDict2(self, df, id1, id2, c1, c2):\n",
    "        # Create a copy of the relevant columns\n",
    "        new_df = df[[id1, id2]].copy()\n",
    "        \n",
    "        # Drop rows with NaN values in either id1 or id2\n",
    "        new_df = new_df.dropna(subset=[id1, id2])\n",
    "        \n",
    "        # Explicitly cast columns to string to avoid dtype compatibility issues\n",
    "        new_df[id1] = new_df[id1].astype(str)\n",
    "        new_df[id2] = new_df[id2].astype(str)\n",
    "        \n",
    "        # Add the prefixes to each column after ensuring there are no NaNs\n",
    "        new_df.loc[:, id1] = c1 + '_' + new_df[id1]\n",
    "        new_df.loc[:, id2] = c2 + '_' + new_df[id2]\n",
    "        \n",
    "        # Remove duplicate rows\n",
    "        new_df = new_df.drop_duplicates()\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def getEdges(self, data, id1, id2):\n",
    "        # Check if data is a DataFrame and extract edges accordingly\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # Extract edges from the DataFrame\n",
    "            EdgesList = list(data[[id1, id2]].itertuples(index=False, name=None))\n",
    "        else:\n",
    "            # Assuming data is a list of dictionaries\n",
    "            EdgesList = [(d[id1], d[id2]) for d in data]\n",
    "        \n",
    "        return EdgesList\n",
    "\n",
    "\n",
    "def G_statistics(G):\n",
    "    Nodes = list(G.nodes())\n",
    "\n",
    "    Patients =    [v for v in Nodes if v[0]=='C']\n",
    "    Visits =      [v for v in Nodes if v[0]=='V']\n",
    "    Medications = [v for v in Nodes if v[0]=='M']\n",
    "    Diagnosis  =  [v for v in Nodes if v[0]=='D']\n",
    "    Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "    Labs       =  [v for v in Nodes if v[0]=='L']\n",
    "    MicroBio   =  [v for v in Nodes if v[0]=='B']\n",
    "    \n",
    "\n",
    "    print(f'number of patients = {len(Patients)}')\n",
    "    print(f'number of visits = {len(Visits)}')\n",
    "    print(f'number of Medication = {len(Medications)}')\n",
    "    print(f'number of Diagnoses = {len(Diagnosis)}')\n",
    "    print(f'number of Procedures = {len(Procedures)}')\n",
    "    print(f'number of Labs = {len(Labs)}')\n",
    "    print(f'number of MicoBio = {len(MicroBio)}')\n",
    "    \n",
    "    print(f'number of Edges = {G.number_of_edges()}')\n",
    "    \n",
    "    print('------------------------------------------\\n')\n",
    "\n",
    "def remove_patients_and_linked_visits(nodes, HG):\n",
    "    '''remove patients and their visits from HG'''\n",
    "    print('Number of PATIENTS to remove: ', len(nodes))\n",
    "    \n",
    "    new_HG = deepcopy(HG)\n",
    "    nodes_to_remove = nodes\n",
    "    for node in nodes:\n",
    "        for v in HG.neighbors(node):\n",
    "            if v[0]=='V':\n",
    "                nodes_to_remove.append(v)\n",
    "        nodes_to_remove.append(node)\n",
    "    print('Number of nodes to remove: ', len(nodes_to_remove))\n",
    "    new_HG.remove_nodes_from(nodes_to_remove)\n",
    "    return new_HG     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataframes...\n",
      "Splitting lab tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2414266/2262445905.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of visits here is 58151\n",
      "Use the patients inside the new DataFrame....\n",
      "Dropping NaN visits\n",
      "General Information:\n",
      "---------------------------\n",
      "Number of Patients = 46517\n",
      "Number of Visits = 58929\n",
      "Number of Diagnosis = 203\n",
      "Number of procedures = 89\n",
      "Number of Medication = 592\n",
      "Number of Lab tests  = 993\n",
      "Number of MicroBio   = 92\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Extracting bipartite networks...\n",
      "\n",
      "Extracting and adding data of Visits\n",
      "\n",
      "Extracting and adding data of Diagnosis\n",
      "\n",
      "Extracting and adding data of Procedures\n",
      "\n",
      "Extracting and adding data of Medications\n",
      "\n",
      "Extracting and adding data of Lab tests\n",
      "\n",
      "Extracting and adding data of MicroBiology tests\n",
      "number of patients = 46437\n",
      "number of visits = 58924\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 0\n",
      "number of MicoBio = 92\n",
      "number of Edges = 926505\n",
      "------------------------------------------\n",
      "\n",
      "Removing isolated nodes\n",
      "Number of PATIENTS to remove:  0\n",
      "Number of nodes to remove:  0\n",
      "number of patients = 46437\n",
      "number of visits = 58924\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 0\n",
      "number of MicoBio = 92\n",
      "number of Edges = 926505\n",
      "------------------------------------------\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# HG_instance = G_class.Generate_HG()\n",
    "HG_instance = Generate_HG()\n",
    "HG = HG_instance.HG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from module1 import generating_HG as G_class\n",
    "# from module1 import XY_preparation as XY\n",
    "\n",
    "# # =================================================================================\n",
    "# # ============================ Extracting Visit-based X and Y =================================\n",
    "# XY_inst = XY.XY_preparation(HG)\n",
    "# XV = XY_inst.X_visit\n",
    "# YV = XY_inst.Y_visit\n",
    "\n",
    "# # ==================================== SAVING =============================================\n",
    "# nx.write_gml(HG, f'{saving_path}/HG.gml')\n",
    "# save_list_as_pickle(MP_inst.Nodes,   saving_path, 'Nodes')\n",
    "# # ==================================== Saving X and Y (visit-based) =================================\n",
    "# torch.save(X, f'{saving_path}/XV.pt')\n",
    "# torch.save(Y, f'{saving_path}/YV.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envGNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
